{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\shawa\\AppData\\Local\\anaconda3\\envs\\transformers\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-5.2826e-02, -2.0603e-01, -1.5062e-02,  8.0527e-02,  8.0432e-03,\n",
      "          4.2127e-02,  5.2671e-02,  1.3812e-02,  3.6934e-02, -6.2355e-02,\n",
      "         -1.9774e-02,  6.6487e-02,  1.9214e-01,  2.2150e-01,  2.3683e-02,\n",
      "         -1.8020e-01,  8.9604e-02, -5.7049e-02, -6.4599e-02,  4.4140e-02,\n",
      "         -7.2506e-02,  5.6609e-02, -6.1662e-02,  6.8534e-02, -3.7086e-03,\n",
      "          3.1052e-02, -2.4233e-02, -3.4827e-02, -1.6331e-02, -1.6136e-01,\n",
      "         -1.1168e-01,  6.6041e-02, -5.1588e-02, -2.0026e-01,  4.9207e-06,\n",
      "         -1.1117e-01, -7.3784e-03,  6.1920e-03, -1.2841e-01,  3.0920e-02,\n",
      "         -1.3898e-01,  3.1287e-01, -9.0167e-02,  6.3635e-02,  1.2263e-01,\n",
      "         -2.3499e-02,  9.0801e-02,  2.0635e-01,  2.4918e-02,  1.3234e-01,\n",
      "          3.2308e-02, -1.9407e-01,  9.4426e-02, -1.5740e-01,  3.2649e-01,\n",
      "         -5.0985e-02,  7.4780e-02, -3.9603e-02,  3.2042e-02,  2.1790e-01,\n",
      "          7.7504e-02,  1.5769e-01, -2.0265e-02, -6.4309e-02,  1.7502e-01,\n",
      "          1.0918e-01,  1.0677e-01, -1.2451e-01,  8.3789e-02,  2.2458e-02,\n",
      "          2.0463e-01, -2.1720e-02, -2.2255e-02,  1.5529e-01, -3.2113e-02,\n",
      "         -1.0898e-01, -3.5673e-02, -1.4105e-02,  5.6713e-02, -3.1313e-02,\n",
      "         -5.5967e-02, -3.5438e-02, -1.1947e-02, -4.9778e-02, -2.5984e-02,\n",
      "          3.7993e-02, -2.1588e-02, -7.7123e-02, -8.6524e-02, -8.7995e-02,\n",
      "          9.4092e-02, -1.0073e-01,  2.9894e-02,  1.1697e-01,  1.2260e-01,\n",
      "         -6.8143e-02, -1.2234e-01, -9.9585e-02,  7.1212e-04, -1.5826e-01,\n",
      "         -1.3306e-05, -1.5082e-02,  3.7609e-03,  1.2811e-01, -9.4992e-03,\n",
      "         -2.0982e-02,  7.2859e-02,  3.3712e-02, -8.9336e-02,  9.6549e-02,\n",
      "          2.0060e-01, -8.4023e-02, -5.7815e-02, -6.1034e-02,  1.2383e-01,\n",
      "          6.0609e-02,  1.3133e-01,  7.0863e-03,  7.5905e-02,  7.7929e-02,\n",
      "          2.1380e-01, -1.6429e-02,  1.4147e-01,  1.0869e-01, -3.4655e-01,\n",
      "          3.5819e-02, -6.1318e-02, -5.3626e-02,  5.1604e-02, -7.4050e-03,\n",
      "         -5.8054e-02,  1.5914e-01,  1.0657e-01, -5.2425e-02,  1.1935e-02,\n",
      "          3.6051e-02,  1.4853e-02,  5.2590e-03,  1.0025e-01, -4.0929e-02,\n",
      "          6.6844e-03,  1.7612e-02, -4.7330e-02, -1.0814e-01,  8.5405e-02,\n",
      "          9.5892e-02,  5.3359e-02, -1.1292e-01,  6.1564e-02,  1.5900e-01,\n",
      "         -1.5654e-01,  2.0006e-01, -7.6817e-02, -8.1906e-02,  2.9352e-01,\n",
      "         -9.3083e-02,  2.4571e-02, -3.2791e-01,  8.6429e-02,  1.0755e-01,\n",
      "          7.9393e-03,  5.5535e-02,  4.0702e-02, -5.8567e-03,  4.3494e-02,\n",
      "          1.2173e-02, -1.6573e-01, -5.4496e-02, -1.2632e-01,  4.2497e-02,\n",
      "         -1.4534e-01, -9.1424e-02, -3.8037e-02,  2.3504e-01,  7.2473e-02,\n",
      "          3.5796e-01,  1.6465e-01, -4.5073e-02, -6.2321e-02, -1.1059e-01,\n",
      "         -9.7150e-02, -4.0147e-01, -1.3457e-01,  1.2664e-01, -1.2140e-01,\n",
      "          8.4781e-02,  3.0472e-02, -3.2395e-02,  1.6151e-02,  7.3396e-02,\n",
      "          5.0267e-02,  1.2065e-02, -1.1602e-02,  9.1103e-02, -7.1149e-02,\n",
      "          4.8578e-02,  6.2883e-02, -1.7362e-02, -1.1352e-01,  4.4769e-02,\n",
      "         -6.4186e-02, -1.3502e-01,  1.8721e-01,  1.2348e-01, -1.0155e-01,\n",
      "         -3.5276e-02,  2.7505e-01, -2.6051e-01,  4.3913e-02,  1.5555e-01,\n",
      "          9.8624e-02,  1.3025e-01, -2.3334e-01,  7.2142e-02, -9.5116e-02,\n",
      "          1.9428e-01, -6.4658e-02,  5.4510e-02, -9.3187e-02, -6.3166e-02,\n",
      "          3.7019e-02,  6.9777e-02, -2.0999e-02,  1.0184e-01,  1.9410e-01,\n",
      "         -2.2228e-01, -1.0197e-01,  4.1347e-02, -1.0727e-01, -6.7476e-02,\n",
      "         -1.2600e-04,  1.3732e-01,  1.4000e-01,  1.6744e-01,  1.7841e-02,\n",
      "         -9.4171e-03, -2.3795e-02, -1.5333e-01, -1.8531e-02, -2.2584e-01,\n",
      "         -4.0249e-02,  1.1662e-02,  3.6498e-02,  1.4515e-01,  1.5313e-01,\n",
      "         -6.6068e-02, -2.2579e-02, -1.3754e-01, -3.6089e-02,  2.4928e-03,\n",
      "         -1.9240e-01, -6.1437e-02, -1.3331e-02,  4.4862e-02,  1.0478e-01,\n",
      "          6.0627e-02, -2.6877e-02, -3.1726e-02, -1.3019e-01,  5.3646e-02,\n",
      "          1.6893e-01, -2.2480e-02,  2.7885e-03, -1.0013e-02,  5.3864e-03,\n",
      "          1.1957e-01, -1.3612e-02,  4.1654e-02, -8.8273e-02,  2.3046e-02,\n",
      "         -1.0588e-01,  1.1439e-01, -1.6258e-02,  1.6617e-02,  1.1716e-02,\n",
      "         -1.3970e-01, -5.4507e-02, -1.2167e-01, -1.4556e-01, -5.1525e-02,\n",
      "          1.5736e-02,  2.4556e-01, -7.5218e-02, -5.0077e-02,  6.9597e-02,\n",
      "          6.4831e-02,  5.8285e-02, -2.2595e-01, -9.4636e-02, -5.3160e-03,\n",
      "          6.5897e-02, -5.0188e-02,  1.1143e-01, -7.6455e-02,  1.9551e-02,\n",
      "          6.9193e-02, -1.9485e-02,  1.6450e-01,  7.9578e-02,  2.9893e-01,\n",
      "          3.6117e-02,  1.5552e-01, -7.7610e-02, -5.2575e-02,  1.6118e-02,\n",
      "          3.0732e-01,  8.9791e-02, -5.8698e-02,  4.7919e-02,  2.0992e-01,\n",
      "          2.5449e-01,  1.5678e-01, -2.1487e-02, -8.3294e-02, -1.0637e-01,\n",
      "          1.3197e-01, -1.7006e-01,  7.3174e-02, -2.8587e-01,  1.0355e-01,\n",
      "         -2.6008e-03, -1.2847e-02,  7.0446e-02,  4.4954e-02,  5.0849e-02,\n",
      "         -5.8252e-02, -1.3285e-01,  1.8409e-01, -9.3849e-02, -1.2069e-01,\n",
      "          7.5711e-02, -1.3555e-02, -1.1509e-01,  1.0041e-01,  9.7024e-02,\n",
      "         -7.3773e-02, -3.0880e-02,  6.1213e-02,  9.6007e-02, -1.7450e-02,\n",
      "         -1.3894e-02,  1.1368e-02,  8.2008e-02, -2.0046e-01, -1.7965e-01,\n",
      "          1.2164e-01, -8.3827e-03, -7.9333e-02, -1.1079e-01, -4.6166e-02,\n",
      "          2.1993e-01,  1.9387e-01, -5.9849e-02, -1.9393e-02, -4.5054e-02,\n",
      "         -3.8401e-02,  1.1716e-02,  1.5238e-01,  1.1850e-02, -1.4110e-01,\n",
      "         -3.5055e-02,  1.2657e-01,  5.4597e-02,  6.8929e-02, -6.2809e-02,\n",
      "         -4.7436e-03, -1.0404e-01, -4.3212e-02,  4.9945e-02,  7.3599e-03,\n",
      "         -1.8354e-01,  1.3698e-01,  7.9665e-02,  1.2108e-01, -5.4931e-02,\n",
      "          4.6902e-02,  3.0097e-02, -2.3880e-02, -2.4533e-02, -2.0440e-02,\n",
      "         -2.8376e-02, -2.3732e-02,  6.9126e-02, -1.7981e-02,  2.7109e-03,\n",
      "          9.7061e-02, -1.0529e-02, -5.0465e-02,  3.1633e-02, -3.2928e-02,\n",
      "          1.0464e-02,  1.8367e-02, -2.2933e-01,  1.4818e-01,  1.0902e-02,\n",
      "          5.6022e-02, -1.1727e-01,  1.7253e-01,  4.3649e-02,  3.6704e-03,\n",
      "         -9.5670e-03,  6.4481e-02,  2.2989e-01,  9.5928e-03, -5.4388e-02,\n",
      "          1.5670e-01,  1.8033e-01,  9.2683e-02,  1.5092e-06,  1.1536e-01,\n",
      "          1.4211e-01, -2.1668e-01,  1.4107e-01,  1.2096e-01,  1.0954e-01,\n",
      "         -1.5802e-01, -9.9247e-02, -7.0584e-02, -4.9207e-02, -1.0566e-01,\n",
      "         -1.3610e-01,  1.6558e-01,  1.2956e-01, -1.9006e-02,  1.2808e-01,\n",
      "          1.1107e-01,  1.8518e-01, -1.1197e-01, -2.1878e-02, -4.9457e-02,\n",
      "         -6.7809e-02,  4.7307e-02, -2.9817e-01,  9.9934e-02, -1.3551e-01,\n",
      "         -1.6178e-01, -9.1718e-02,  1.1284e-02, -8.8229e-02, -1.3606e-01,\n",
      "          8.2637e-02,  5.4929e-02,  1.5502e-01, -3.7531e-03, -9.7992e-02,\n",
      "          2.8705e-01, -6.1422e-03,  5.2636e-02, -2.0315e-02, -7.4537e-02,\n",
      "          1.2748e-01,  2.7230e-02, -1.5072e-01, -1.5040e-01, -2.1654e-02,\n",
      "         -2.3607e-02, -2.3599e-02, -3.0547e-02, -3.2098e-02, -1.1813e-01,\n",
      "         -1.6186e-02,  6.7826e-02, -1.8355e-01, -8.0063e-02, -4.7524e-02,\n",
      "          1.0578e-02, -1.3066e-01, -1.6951e-01, -4.1898e-02, -1.4086e-01,\n",
      "          2.7154e-03,  7.2226e-02, -5.2052e-02,  2.8050e-02, -1.7113e-01,\n",
      "         -9.7431e-02, -1.5737e-01, -1.8818e-01, -1.4615e-01, -2.9051e-02,\n",
      "          8.7170e-02,  1.6192e-02, -1.6390e-01, -2.9475e-03, -1.2085e-01,\n",
      "         -3.9761e-02, -2.3331e-02,  3.3708e-02,  7.7426e-02,  2.1311e-02,\n",
      "          7.3706e-03, -1.7191e-01, -4.6229e-02, -1.0814e-01, -1.2724e-01,\n",
      "         -5.1487e-03,  6.2109e-02, -8.1826e-02,  1.7518e-01,  1.5382e-01,\n",
      "          1.1550e-01,  3.6860e-02, -1.7082e-01,  3.1412e-02, -8.2700e-02,\n",
      "         -2.2033e-02, -5.3850e-02,  7.4519e-02, -5.9954e-02,  2.3834e-02,\n",
      "          3.2157e-02,  1.1793e-02, -8.4555e-02, -1.1166e-01, -7.0135e-02,\n",
      "          3.7913e-02, -1.7293e-01, -6.5552e-02, -1.3996e-01,  3.0627e-02,\n",
      "          7.0890e-03, -4.0628e-02,  7.3877e-02, -1.0283e-01, -5.4695e-02,\n",
      "         -2.7624e-02,  6.7827e-02, -6.0011e-02, -1.0947e-01,  5.1924e-02,\n",
      "         -1.5782e-01,  5.2761e-02,  2.7032e-04,  1.1889e-01, -3.8017e-02,\n",
      "          4.8068e-03,  7.6400e-02,  1.2463e-02,  9.5243e-03, -8.0999e-02,\n",
      "          2.4516e-01, -1.3399e-01,  2.3695e-02,  3.9460e-02,  4.0475e-02,\n",
      "         -2.5094e-02,  2.5669e-02, -1.3523e-01, -1.5443e-01, -3.3353e-03,\n",
      "          4.0105e-03,  2.2330e-01,  2.5655e-02,  8.7124e-02, -1.2438e-01,\n",
      "         -1.7672e-32, -9.3084e-02, -1.6630e-01, -8.1601e-02,  2.6406e-01,\n",
      "         -1.0380e-01, -1.2399e-01, -2.5233e-02,  9.3220e-02, -7.2854e-02,\n",
      "         -7.2329e-03,  6.7622e-03,  1.4261e-02,  7.5034e-02,  7.9135e-02,\n",
      "         -9.4641e-02, -1.2757e-01,  6.6307e-03, -2.9041e-02,  3.4111e-02,\n",
      "         -8.6074e-02, -4.8244e-02, -6.6281e-02,  1.0880e-01, -1.8582e-02,\n",
      "          1.3614e-01, -4.2240e-02, -1.6560e-01,  3.0248e-02,  6.7290e-02,\n",
      "          9.9746e-02, -1.2170e-01, -3.4271e-02, -4.8394e-02, -1.1394e-01,\n",
      "          3.6624e-02,  4.4853e-01, -8.8426e-02, -1.3213e-01, -1.3187e-01,\n",
      "         -2.6933e-02, -1.2403e-01, -3.3787e-02, -1.0432e-01, -1.0876e-01,\n",
      "          4.2176e-02,  2.2670e-02,  1.3639e-02, -2.8917e-02,  6.5431e-02,\n",
      "          1.3256e-01, -1.7270e-01,  2.3307e-02,  5.7544e-02,  1.7188e-02,\n",
      "          4.5047e-02,  2.9156e-01,  7.1829e-02, -3.1102e-01, -4.6567e-02,\n",
      "          4.0130e-03,  6.0337e-02,  2.7802e-02,  2.8681e-03,  1.3427e-01,\n",
      "         -1.2319e-01, -4.1627e-02, -1.9405e-01, -4.1900e-02, -5.8989e-02,\n",
      "         -7.3707e-03, -2.5334e-02,  1.0105e-01, -5.9293e-02,  6.8627e-02,\n",
      "         -2.1982e-01, -8.1255e-02, -2.4401e-02, -9.1921e-03,  3.4095e-02,\n",
      "          4.6202e-02, -1.8504e-01, -1.0500e-01,  1.3353e-01, -2.7661e-02,\n",
      "         -5.9658e-02, -1.1054e-01, -8.5018e-03, -9.0334e-02,  6.5435e-03,\n",
      "         -1.7751e-02, -4.6239e-02, -5.2514e-02,  6.6799e-04,  2.0867e-02,\n",
      "         -4.0698e-02, -2.9997e-02,  6.5651e-02, -2.3439e-02, -8.8175e-02,\n",
      "         -6.1117e-02,  2.8758e-02, -9.4965e-03,  3.1319e-02,  7.3299e-03,\n",
      "          6.1147e-02,  7.1484e-02, -7.5066e-02,  3.6220e-02, -2.0018e-01,\n",
      "         -1.5087e-02,  4.6973e-02, -1.6619e-01,  4.2120e-02,  1.3036e-01,\n",
      "         -7.4441e-02,  4.1843e-02,  6.1072e-03, -2.0959e-02, -8.9532e-02,\n",
      "          1.2876e-02,  5.4986e-02,  6.2841e-02,  4.5454e-02,  9.4277e-02,\n",
      "         -1.5446e-01,  8.1834e-02, -1.4104e-01,  3.6060e-02,  1.6249e-01,\n",
      "          4.0842e-02,  5.6648e-02,  6.1414e-02,  6.4806e-07,  1.8586e-01,\n",
      "          8.7871e-03,  4.7477e-02,  7.8066e-02, -1.2731e-02,  4.3704e-05,\n",
      "          4.8537e-02,  8.8935e-02,  1.3548e-01, -1.1983e-01, -9.4124e-03,\n",
      "         -9.1461e-02,  7.9785e-02,  7.5332e-02, -1.2798e-01, -1.8166e-01,\n",
      "         -4.1476e-02,  1.2529e-01,  2.4481e-02,  2.8564e-02,  2.7220e-01,\n",
      "          1.0438e-01,  1.0137e-01,  1.8387e-01,  2.2148e-02,  5.5984e-03,\n",
      "          2.5877e-02, -5.6554e-02,  6.9873e-02, -1.7754e-01, -1.8685e-01,\n",
      "         -2.2572e-01, -3.0041e-02, -2.3541e-02,  7.6063e-03, -2.4386e-02,\n",
      "          1.6798e-01,  1.1228e-01, -4.1047e-02,  1.0708e-02,  7.1122e-02,\n",
      "         -4.4015e-02, -7.3743e-02, -2.1821e-01, -6.1897e-03,  6.1390e-03,\n",
      "          1.4485e-01, -1.0237e-01,  3.0915e-02, -5.8005e-02,  1.0876e-01,\n",
      "          7.6354e-02,  2.9971e-02, -1.0685e-01,  1.0116e-01,  2.8585e-02,\n",
      "         -1.5748e-02,  4.9498e-02, -3.6757e-02,  9.4306e-02, -1.9894e-01,\n",
      "         -2.6292e-02, -8.3996e-02,  1.0341e-01,  1.7068e-01, -1.0109e-02,\n",
      "          5.5283e-02,  3.5422e-34, -3.1977e-02, -5.5620e-02,  3.5582e-02,\n",
      "          2.0668e-02,  7.9360e-02,  7.2024e-03,  1.4475e-01, -4.4768e-02,\n",
      "          5.5969e-02, -2.1433e-01, -1.4558e-01]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "text = \"Your input text goes here.\"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "embeddings = outputs.last_hidden_state.mean(dim=1)  # You can adjust the aggregation method\n",
    "print(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)a8e1d/.gitattributes: 100%|██████████| 1.18k/1.18k [00:00<00:00, 586kB/s]\n",
      "Downloading (…)_Pooling/config.json: 100%|██████████| 190/190 [00:00<00:00, 64.0kB/s]\n",
      "Downloading (…)b20bca8e1d/README.md: 100%|██████████| 10.6k/10.6k [00:00<00:00, 5.28MB/s]\n",
      "Downloading (…)0bca8e1d/config.json: 100%|██████████| 571/571 [00:00<00:00, 284kB/s]\n",
      "Downloading (…)ce_transformers.json: 100%|██████████| 116/116 [00:00<00:00, 55.6kB/s]\n",
      "Downloading (…)e1d/data_config.json: 100%|██████████| 39.3k/39.3k [00:00<00:00, 191kB/s]\n",
      "Downloading pytorch_model.bin: 100%|██████████| 438M/438M [01:23<00:00, 5.24MB/s] \n",
      "Downloading (…)nce_bert_config.json: 100%|██████████| 53.0/53.0 [00:00<00:00, 26.5kB/s]\n",
      "Downloading (…)cial_tokens_map.json: 100%|██████████| 239/239 [00:00<00:00, 39.9kB/s]\n",
      "Downloading (…)a8e1d/tokenizer.json: 100%|██████████| 466k/466k [00:00<00:00, 702kB/s]\n",
      "Downloading (…)okenizer_config.json: 100%|██████████| 363/363 [00:00<00:00, 182kB/s]\n",
      "Downloading (…)8e1d/train_script.py: 100%|██████████| 13.1k/13.1k [00:00<00:00, 6.55MB/s]\n",
      "Downloading (…)b20bca8e1d/vocab.txt: 100%|██████████| 232k/232k [00:00<00:00, 465kB/s]\n",
      "Downloading (…)bca8e1d/modules.json: 100%|██████████| 349/349 [00:00<00:00, 174kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new movie is awesome \t\t The new movie is so great \t\t Score: 0.9101\n",
      "The cat sits outside \t\t The cat plays in the garden \t\t Score: 0.6738\n",
      "I love pasta \t\t Do you like pizza? \t\t Score: 0.5189\n",
      "I love pasta \t\t The new movie is so great \t\t Score: 0.2035\n",
      "The new movie is awesome \t\t Do you like pizza? \t\t Score: 0.1931\n",
      "The new movie is so great \t\t Do you like pizza? \t\t Score: 0.1788\n",
      "I love pasta \t\t The new movie is awesome \t\t Score: 0.1752\n",
      "I love pasta \t\t The cat plays in the garden \t\t Score: 0.1108\n",
      "The cat sits outside \t\t The new movie is so great \t\t Score: 0.1059\n",
      "The cat plays in the garden \t\t Do you like pizza? \t\t Score: 0.0911\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "model = SentenceTransformer('all-mpnet-base-v2')\n",
    "\n",
    "# Single list of sentences\n",
    "sentences = ['The cat sits outside',\n",
    "             'A man is playing guitar',\n",
    "             'I love pasta',\n",
    "             'The new movie is awesome',\n",
    "             'The cat plays in the garden',\n",
    "             'A woman watches TV',\n",
    "             'The new movie is so great',\n",
    "             'Do you like pizza?']\n",
    "\n",
    "#Compute embeddings\n",
    "embeddings = model.encode(sentences, convert_to_tensor=True)\n",
    "\n",
    "#Compute cosine-similarities for each sentence with each other sentence\n",
    "cosine_scores = util.cos_sim(embeddings, embeddings)\n",
    "\n",
    "#Find the pairs with the highest cosine similarity scores\n",
    "pairs = []\n",
    "for i in range(len(cosine_scores)-1):\n",
    "    for j in range(i+1, len(cosine_scores)):\n",
    "        pairs.append({'index': [i, j], 'score': cosine_scores[i][j]})\n",
    "\n",
    "#Sort scores in decreasing order\n",
    "pairs = sorted(pairs, key=lambda x: x['score'], reverse=True)\n",
    "\n",
    "for pair in pairs[0:10]:\n",
    "    i, j = pair['index']\n",
    "    print(\"{} \\t\\t {} \\t\\t Score: {:.4f}\".format(sentences[i], sentences[j], pair['score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimilarityFinder:\n",
    "\n",
    "    def __init__(self, model_name):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def calculate_embeddings(self, sentences):\n",
    "        return self.model.encode(sentences, convert_to_tensor=True)\n",
    "\n",
    "    def calculate_similarity(self, embeddings1, embeddings2):\n",
    "        return util.cos_sim(embeddings1, embeddings2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
